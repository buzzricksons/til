# [대규모 시스템 설계 기초]
- 1장. 사용자 수에 따른 규모 확장성: https://newwisdom.tistory.com/114
- 2장. 개략적인 규모 추정: https://newwisdom.tistory.com/115
- 3장. 시스템 설계 면접 공략법: https://newwisdom.tistory.com/116
- 4장. 처리율 제한 장치의 설계: https://newwisdom.tistory.com/117
- 5장. 안정 해시 설계: https://newwisdom.tistory.com/118
- 6장. 키-값 저장소 설계: https://newwisdom.tistory.com/120

# 시스템 확장을 위한 기법
- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 한 많은 데이터를 캐시할 것
- 여러 데이터 센터를 지원할 것
- 정적 콘텐츠는 CDN을 통해 서비스 할것
- 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
- 각 계층은 독립적 서비스로 분할할것
- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것

# 개략적인 규모추정 예
## 가정
- 월간 능동 사용자(monthly active user)는 3억(300million) 명이다.
- 50%의 사용자가 트위터를 매일 사용한다.
- 평균적으로 각 사용자는 매일 2건의 트윗을 올린다.
- 미디어를 포함하는 트윗은 10% 정도다.
- 데이터는 5년간 보관된다.

## 추정
### QPS(Query Per Second) 추정지
- 일간 능동 사용자(Daily Active User, DAU) = 3억 x 50% = 1.5억(150million)
- QPS = 1.5억 x 2트윗 / 24시간 / 60분 / 60초 = 약 3,500
- 최대 QPS(Peek QPS) = 2 x QPS = 약7,000
  
### 미디어 저장을 위한 저장소 요구량
- 평균 트윗 크기
  - tweet_id에 64바이트
  - 텍스트에 140바이트
  - 미디어에 1MB
- 미디어 저장소 요구량: 1.5억 x 2 x 10% x 1MB = 30TB/일
- 5년간 미디어를 보관하기 위한 저장소 요구량: 30TB x 365 x 5 = 약55PB

# 처리율 제한 알고리즘
## 토큰 버킷 알고리즘
- 2개의 인자
  - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
  - 토큰 공급률(refill rate): 초당 몇 개의 토큰이 버킷에 공급되는가
- 통상적으로, API 엔드포인트마다 별도의 버킷을 둠. 예를 들어, 사용자마다 하루에 한 번만 포스팅을 할 수 있고, 친구는 150명까지 추가할 수 있고, 좋아요 버튼을 다섯 번까지만 누를 수 있다면, 사용자마다 3개의 버킷을 두어야 할것이다.
- IP주소별로 처리율 제한을 적용해야 한다면 IP주소마다 버킷을 하나씩 할당해야함.
- 시스템의 처리율이 초당 10,000개 요청으로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하도록 해야 함.

### 장점
- 구현이 쉽다.
- 메모리 사용 측면에서도 효율적
- 짧은 시간에 집중되는 트래픽 처리도 가능. 버킷에 남은 토큰이 이씩만 하면 요청은 시스템에 전달됨

### 단점
- 이 알고리즘은 버킷 크기와 토큰 공급률이라는 두 개 인자를 가지고 있는데 이 값을 적절하게 튜닝하는것은 까다로운 일이 될것이다.

## 누출 버킷 알고리즘
- 두개의 인자
  - 버킷 크기: 큐 사이즈와 같은 값. 큐에는 처리될 항목들이 보관 됨.
  - 처리율(outflow rate): 지정된 시간당 몇 개의 항목을 처리할 지 지정하는 값. 보통 초단위로 표현됨.

### 장점
- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적.
- 고정된 처리율을 갖고 있기 때문에 안정적 출력(stable outflow rate)이 필요한 경우에 적합함

### 단점
- 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 됨.
- 두 개 인자를 갖고 있는데, 이들을 올바르게 튜닝하기 어려울 수 있음.

## 고정 윈도 카운터 알고리즘
- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
- 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.
- 이 카운터의 값이 사전에 설정된 임계치(threshold)에 도달하면 새로운 요청은 새 윈도가 열릴때까지 버려진다.

### 장점
- 메모리 효율이 좋다.
- 이해하기 쉽다.
- 윈도가 닫히는 시점에 카운터를 초기화 하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

### 단점
- 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 됨.

## 이동 윈도 로깅 알고리즘
고정 윈도 카운터 알고리즘의 단점을 개선. 고정 윈도 카운터 알고리즘은 윈도 경계부근에 트래픽이 집중되는 경우 시스템에 설정된 한도보다 많은 요청을 처리하게 되기 때문.

### 장점
- 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다. 어느순간의 윈도를 보더라도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.

### 단점
- 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.

## 이동 위도 카운터 알고리즘
### 장점
- 이전 시간대에 평균 처리율에 따라 현재 윈도의 상태를 게산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
- 메모리 효율이 좋다.

### 단점
- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. 하지만 이 문제는 생각만큼 심각한 것은 아닌데, 클라우드 플레어가 실시했던 실험에 따르면 40억개의 요청 가운데 시스템의 실제 상태와 맞지 않게 허용되거나 버려진 요청은 0.003%에 불과했다.



